{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBzaC1fditSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79bbc0b0-d1c4-4068-f36f-da884f1f5b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path of the notebook file (e.g., .txt, .md): NLP.txt\n",
            "Enter the number of MCQs to generate: 10\n",
            "\n",
            "Generated Interview MCQs:\n",
            "\n",
            "Question 1: Classifying text as _________ or not _________.\n",
            "6.\n",
            "Options:\n",
            "a) Classifying\n",
            "b) Related Term\n",
            "c) text\n",
            "d) spam\n",
            "Correct Answer: spam\n",
            "\n",
            "\n",
            "Question 2: _________ Answering\n",
            "Retrieval-Based QA: Finding and returning the most relevant text passage in response to a query.\n",
            "\n",
            "Options:\n",
            "a) Question\n",
            "b) response\n",
            "c) passage\n",
            "d) query\n",
            "Correct Answer: Question\n",
            "\n",
            "\n",
            "Question 3: Smarter _________ allows a chatbot to understand a customer’s request can enable “_________ like you talk” functionality (much like you could query Siri) rather than focusing on keywords or topics.\n",
            "Options:\n",
            "a) functionality\n",
            "b) search\n",
            "c) topics\n",
            "d) allows\n",
            "Correct Answer: search\n",
            "\n",
            "\n",
            "Question 4: _________ Extraction\n",
            "Extracting meaningful features from the text data that can be used for various NLP tasks.\n",
            "\n",
            "\n",
            "Options:\n",
            "a) Extraction\n",
            "b) text\n",
            "c) NLP\n",
            "d) Feature\n",
            "Correct Answer: Feature\n",
            "\n",
            "\n",
            "Question 5: 5. Model Selection and Training\n",
            "Selecting and training a machine _________ or deep _________ model to perform specific NLP tasks.\n",
            "\n",
            "\n",
            "Options:\n",
            "a) model\n",
            "b) perform\n",
            "c) learning\n",
            "d) Selection\n",
            "Correct Answer: learning\n",
            "\n",
            "\n",
            "Question 6: Natural Language Toolkits (_________) and other libraries: _________ is a popular open-source library in Python that provides tools for NLP tasks such as tokenization, stemming, and part-of-speech tagging.\n",
            "Options:\n",
            "a) tagging\n",
            "b) Natural\n",
            "c) NLTK\n",
            "d) libraries\n",
            "Correct Answer: NLTK\n",
            "\n",
            "\n",
            "Question 7: Stopword _________: Removing common words that do not contribute significant meaning, such as “and,” “the,” “is.”\n",
            "Punctuation _________: Removing punctuation marks.\n",
            "\n",
            "Options:\n",
            "a) Stopword\n",
            "b) contribute\n",
            "c) meaning\n",
            "d) Removal\n",
            "Correct Answer: Removal\n",
            "\n",
            "\n",
            "Question 8: From basic _________ like tokenization and part-of-speech tagging to advanced applications like sentiment analysis and machine translation, the impact of NLP is evident across various domains.\n",
            "Options:\n",
            "a) tasks\n",
            "b) domains\n",
            "c) NLP\n",
            "d) machine\n",
            "Correct Answer: tasks\n",
            "\n",
            "\n",
            "Question 9: 4. Information _________\n",
            "Entity _________: Identifying specific entities and their relationships within the text.\n",
            "\n",
            "Options:\n",
            "a) Identifying\n",
            "b) Extraction\n",
            "c) text\n",
            "d) Information\n",
            "Correct Answer: Extraction\n",
            "\n",
            "\n",
            "Question 10: _________ Storage: Storing the collected text data in a structured format, such as a database or a collection of documents.\n",
            "\n",
            "Options:\n",
            "a) Data\n",
            "b) Storing\n",
            "c) database\n",
            "d) data\n",
            "Correct Answer: Data\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def generate_interview_mcq(text,num_questions):\n",
        "    if not text:\n",
        "        print(\"Error: No text provided.\")\n",
        "        return []\n",
        "\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "\n",
        "    if len(sentences) < num_questions:\n",
        "        print(f\"Warning: Only {len(sentences)} unique sentences found. Some will be reused.\")\n",
        "        sentences = (sentences * (num_questions // len(sentences) + 1))[:num_questions]\n",
        "\n",
        "\n",
        "    candidate_sentences = random.sample(sentences, min(len(sentences), num_questions * 2))\n",
        "\n",
        "    mcq = []\n",
        "\n",
        "    for sentence in candidate_sentences:\n",
        "        sent_doc = nlp(sentence)\n",
        "\n",
        "        keywords = [token.text for token in sent_doc if token.pos_ in {'NOUN', 'PROPN', 'VERB'}]\n",
        "\n",
        "        if len(keywords) < 2:\n",
        "            continue\n",
        "        keyword_counts = Counter(keywords)\n",
        "        if not keyword_counts:\n",
        "            continue\n",
        "\n",
        "\n",
        "        correct_answer = keyword_counts.most_common(1)[0][0]\n",
        "        question_stem = sentence.replace(correct_answer, \"_________\")\n",
        "\n",
        "\n",
        "        distractors = list(set(keywords) - {correct_answer})\n",
        "\n",
        "\n",
        "        while len(distractors) < 3:\n",
        "            distractors.append(\"Related Term\")\n",
        "\n",
        "\n",
        "        answer_choices = [correct_answer] + random.sample(distractors, min(len(distractors), 3))\n",
        "        random.shuffle(answer_choices)\n",
        "\n",
        "        mcq.append((question_stem, answer_choices, correct_answer))\n",
        "\n",
        "\n",
        "        if len(mcq) == num_questions:\n",
        "            break\n",
        "\n",
        "\n",
        "    while len(mcq) < num_questions:\n",
        "        extra_question = random.choice(mcq)\n",
        "        new_stem = extra_question[0].replace(\"_________\", \"______\")\n",
        "        new_choices = random.sample(extra_question[1], len(extra_question[1]))\n",
        "        mcq.append((new_stem, new_choices, extra_question[2]))\n",
        "\n",
        "    return mcq\n",
        "\n",
        "\n",
        "file_path = input(\"Enter the path of the notebook file (e.g., .txt, .md): \").strip()\n",
        "\n",
        "try:\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        user_text = file.read()\n",
        "\n",
        "\n",
        "    num_questions = int(input(\"Enter the number of MCQs to generate: \").strip())\n",
        "\n",
        "    mcqs = generate_interview_mcq(user_text, num_questions=num_questions)\n",
        "\n",
        "\n",
        "    if mcqs:\n",
        "        print(\"\\nGenerated Interview MCQs:\\n\")\n",
        "        for i, (question, options, correct) in enumerate(mcqs, 1):\n",
        "            print(f\"Question {i}: {question}\")\n",
        "            print(\"Options:\")\n",
        "            for idx, option in enumerate(options):\n",
        "                print(f\"{chr(97 + idx)}) {option}\")\n",
        "            print(\"Correct Answer:\", correct)\n",
        "            print(\"\\n\")\n",
        "    else:\n",
        "        print(\"No suitable MCQs could be generated. Try providing a more relevant file.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file was not found. Please check the file path and try again.\")\n",
        "except ValueError:\n",
        "    print(\"Error: Please enter a valid number for the MCQs.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1cGrZQoAm401"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}